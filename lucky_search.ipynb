{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feeling Lucky\n",
    "import urllib\n",
    "def lucky_search(index, ranks, keyword):\n",
    "    pages = lookup(index, keyword)\n",
    "    if not pages:\n",
    "        return None\n",
    "    best_page = pages[0]\n",
    "    for page in pages:\n",
    "        if ranks[page] > ranks[best_page]:\n",
    "            best_page = page\n",
    "    return best_page\n",
    "\n",
    "def ordered_search(index, ranks, keyword):\n",
    "    pages = lookup(index, keyword)\n",
    "    return quicksort_pages(pages, ranks)\n",
    "\n",
    "def quicksort_pages(pages, ranks):\n",
    "    if not pages or len(pages) <= 1:\n",
    "        return pages\n",
    "    else:\n",
    "        # find a pivot\n",
    "        pivot = ranks[pages[0]]\n",
    "        worse = []\n",
    "        better = []\n",
    "        for page in pages[1:]:\n",
    "            if ranks[page] > pivot:\n",
    "                better.append(page)\n",
    "            else:\n",
    "                worse.append(page)\n",
    "        return quicksort_pages(better, ranks) + [pages[0]] + quicksort_pages(worse, ranks)\n",
    "\n",
    "def get_page(url):\n",
    "    return urllib.request.urlopen(url).read()\n",
    "\n",
    "def get_next_target(page):\n",
    "    start_link = page.find('<a href=')\n",
    "    if start_link == -1: \n",
    "        return None, 0\n",
    "    start_quote = page.find('\"', start_link)\n",
    "    end_quote = page.find('\"', start_quote + 1)\n",
    "    url = page[start_quote + 1:end_quote]\n",
    "    return url, end_quote\n",
    "\n",
    "def get_all_links(page):\n",
    "    links = []\n",
    "    while True:\n",
    "        url, endpos = get_next_target(page)\n",
    "        if url:\n",
    "            links.append(url)\n",
    "            page = page[endpos:]\n",
    "        else:\n",
    "            break\n",
    "    return links\n",
    "\n",
    "def union(a, b):\n",
    "    for e in b:\n",
    "        if e not in a:\n",
    "            a.append(e)\n",
    "\n",
    "def add_page_to_index(index, url, content):\n",
    "    words = content.split()\n",
    "    for word in words:\n",
    "        add_to_index(index, word, url)\n",
    "        \n",
    "def add_to_index(index, keyword, url):\n",
    "    if keyword in index:\n",
    "        index[keyword].append(url)\n",
    "    else:\n",
    "        index[keyword] = [url]\n",
    "    \n",
    "def lookup(index, keyword):\n",
    "    if keyword in index:\n",
    "        return index[keyword]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def crawl_web(seed): # returns index, graph of inlinks\n",
    "    tocrawl = [seed]\n",
    "    crawled = []\n",
    "    graph = {}  # <url>, [list of pages it links to]\n",
    "    index = {} \n",
    "    while tocrawl: \n",
    "        page = tocrawl.pop()\n",
    "        if page not in crawled:\n",
    "            content = get_page(page)\n",
    "            add_page_to_index(index, page, content)\n",
    "            outlinks = get_all_links(content)\n",
    "            graph[page] = outlinks\n",
    "            union(tocrawl, outlinks)\n",
    "            crawled.append(page)\n",
    "    return index, graph\n",
    "\n",
    "def compute_ranks(graph):\n",
    "    d = 0.8 # damping factor\n",
    "    numloops = 10\n",
    "    \n",
    "    ranks = {}\n",
    "    npages = len(graph)\n",
    "    for page in graph:\n",
    "        ranks[page] = 1.0 / npages\n",
    "    \n",
    "    for i in range(0, numloops):\n",
    "        newranks = {}\n",
    "        for page in graph:\n",
    "            newrank = (1 - d) / npages\n",
    "            for node in graph:\n",
    "                if page in graph[node]:\n",
    "                    newrank = newrank + d * (ranks[node] / len(graph[node]))\n",
    "            newranks[page] = newrank\n",
    "        ranks = newranks\n",
    "    return ranks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
